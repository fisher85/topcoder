{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://contest.yandex.ru/contest/12899/problems/\n",
    "\n",
    "Файлы из описания можно взять тут — https://yadi.sk/d/uHe-XpI7pcnZKA\n",
    "\n",
    "План:\n",
    "1. Разбираемся с implicit.als, играем настройками. https://medium.com/wttj-tech/exploring-collaborative-filtering-for-job-recommendations-91f09b7b536c\n",
    "2. Пробуем дополнить матрицу лайками и избранным.\n",
    "3. Пробуем из предсказания удалить те картинки, которые уже были просмотрены. Это уже было сделано."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попытки:\n",
    "1. Базовое решение, 4.2 балла\n",
    "2. Увеличиваем число итераций als.fit c 30 до 35, 4.29. Смысла бороться за сотые нет, там лидеры к 30 баллам приближаются.\n",
    "3. Умножаем матрицу на коэффициент alpha, как это делают авторы статьи и метода http://yifanhu.net/PUB/cf.pdf. Первая проба 15 (получил сразу 7.14), вторая 40 (6.34). Вернул до 30 итераций, иначе ноут выключается.\n",
    "4. alpha = 10, iters = 30. 6.62.\n",
    "5. aplha = 15, iters = 30.\n",
    "6. aplha = 15, factors=10, iters = 35.\n",
    "7. aplha = 15, factors=20, regularization=0.1, iterations=20. Добавил явно filter_already_liked_items=True, хотя параметр по умолчанию должен стоять. Это для того, чтобы в предсказаниях не было картинок, которые пользователь уже выбрал ранее. Этих рекомендаций по условию задачи не должно быть. 6.89 (посылка 20650335)\n",
    "8. aplha = 15, factors=20, regularization=0.1, iterations=35. Сбой.\n",
    "9. Надоело запускать ноут, нужно железо правильно готовить. И не могу повторить опыт 7.14, на будущее - нужно все версии исходников коммитить.\n",
    "10. alpha = 15, factors=10, iters = 30. Добавляю train_likes.zip с весом 1 и train_shares.zip с весом 1. Просто добавляю строки при формировании coo_matrix. Получил 5.49 (посылка 20650558). Плохо, значит alpha вредит в этом случае.\n",
    "11. aplha = 5, factors=10, iters = 30. Добавляю train_likes.zip с весом 1 и train_shares.zip с весом 1. 7.36 (посылка 20650720).\n",
    "12. Избранное - важнее. Пробуем вес share = 2. aplha = 5, factors=10, iters = 30. Добавляю train_likes.zip с весом 1 и train_shares.zip с весом 2. Сбой.\n",
    "13. **aplha = 5, factors=20, regularization=0.1, iterations=20. Добавляю train_likes.zip с весом 1 и train_shares.zip с весом 2. 11.33 (посылка 20651056).**\n",
    "14. alpha = 3. factors=20, regularization=0.1, iterations=20. Добавляю train_likes.zip с весом 2 и train_shares.zip с весом 3. 10.35 (посылка 20651210).\n",
    "15. aplha = 5, factors=20, regularization=0.01, iterations=20. Добавляю train_likes.zip с весом 1 и train_shares.zip с весом 2. 11.03. (посылка 20651388).\n",
    "16. aplha = 3, factors=20, regularization=0.1, iterations=20. Добавляю train_likes.zip с весом 1 и train_shares.zip с весом 2. 11.04. (посылка 20651492).\n",
    "17. aplha = 5, factors=20, regularization=0.1, iterations=25. Добавляю train_likes.zip с весом 1 и train_shares.zip с весом 2. 10.89. (посылка 20651580).\n",
    "18. aplha = 5, factors=25, regularization=0.1, iterations=20. Добавляю train_likes.zip с весом 1 и train_shares.zip с весом 2. . (посылка 20651580).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что не учитываем:\n",
    "1. Дату. Пока не умею."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "import implicit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Читаем клики пользователей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id       2360862\n",
      "picture_id    2360862\n",
      "day           2360862\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_clicks = pd.read_csv('train_clicks.csv')\n",
    "print(train_clicks.count())\n",
    "# train_clicks[:17]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пробуем дополнить клики лайками и избранным"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 5\n",
    "\n",
    "train_likes = pd.read_csv('train_likes.csv')\n",
    "train_shares = pd.read_csv('train_shares.csv')\n",
    "\n",
    "train_clicks = pd.concat([train_clicks, train_likes])\n",
    "# train_clicks = pd.concat([train_clicks, train_likes])\n",
    "\n",
    "train_clicks = pd.concat([train_clicks, train_shares])\n",
    "train_clicks = pd.concat([train_clicks, train_shares])\n",
    "# train_clicks = pd.concat([train_clicks, train_shares])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = train_clicks.user_id\n",
    "items = train_clicks.picture_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "446188"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# По условиям задачи было 200000 пользователей, а реально Яндекс обманул - дал 445357\n",
    "# users.value_counts()\n",
    "users.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаём разреженную матрицу пользователь — объект. Используем модель **coo_matrix**, она позволяет быстро сформировать матрицу, зная координаты значений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_item = coo_matrix((np.ones_like(users), (users, items)))*alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод разреженной матрицы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1442, 546149) 5\n"
     ]
    }
   ],
   "source": [
    "# Вот это жестко, когда третий элемент имеет col index = 1242875\n",
    "# print(user_item.todense())\n",
    "for row, col, value in zip(user_item.row, user_item.col, user_item.data):\n",
    "    print(\"({0}, {1}) {2}\".format(row, col, value))\n",
    "    if row > 1000: break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве модели будем использовать разложение матрицы с помощью метода ALS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но для начала убираем распараллеливание, иначе ноут выключается от таких нагрузок :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# http://diracprogram.org/doc/release-12/installation/mkl.html\n",
    "import os\n",
    "print(os.environ.get('MKL_NUM_THREADS'))\n",
    "if np.__config__.get_info('blas_mkl_info') and os.environ.get('MKL_NUM_THREADS') != '1':\n",
    "    os.environ[\"MKL_NUM_THREADS\"] = '1'\n",
    "    os.environ[\"MKL_DYNAMIC\"] = \"FALSE\"\n",
    "    os.environ[\"OMP_DYNAMIC\"] = \"FALSE\"\n",
    "    os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "    \n",
    "print(os.environ.get('MKL_NUM_THREADS'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = implicit.als.AlternatingLeastSquares(factors=10, iterations=30)\n",
    "# model = implicit.als.AlternatingLeastSquares(factors=10, iterations=35)\n",
    "model = implicit.als.AlternatingLeastSquares(factors=25, regularization=0.1, iterations=20)\n",
    "# factors=20, regularization=0.1, iterations=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20.0/20 [01:41<00:00,  4.94s/it]\n"
     ]
    }
   ],
   "source": [
    "model.fit(user_item.T.tocsr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прочитаем идентификаторы пользователей, для которых нам нужно сделать предсказания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_users = pd.read_csv('test_users.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_item_csr = user_item.tocsr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для каждого пользователя найдём 100 самых релевантных изображений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for user_id in test_users.user_id.values:\n",
    "    items = [i[0] for i in model.recommend(user_id, user_item_csr, N=100, filter_already_liked_items=True)]\n",
    "    rows.append(items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отформатируем идентификаторы как нужно для ответа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_users['predictions'] = list(map(lambda x: ' '.join(map(str, x)), rows))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И запишем предсказания в файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_users.to_csv('predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
